{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d35456",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## CSCI 5845: Natural Language Processing\n",
    "\n",
    "### Student Information\n",
    "- **Name**: Lohit Akkineni\n",
    "- **Instructor**: Willbert Hawley\n",
    "\n",
    "### Project Overview\n",
    "This project involves building and evaluating several neural network models to perform language identification. The dataset consists of approximately 10,000 entries covering 17 different languages. The goal is to accurately classify the language of each text entry using three distinct types of neural network architectures: Dense Neural Networks, Convolutional Neural Networks (CNN), and Long Short-Term Memory (LSTM) Networks.\n",
    "\n",
    "### Objectives\n",
    "- To apply and compare different neural network architectures for the task of language identification.\n",
    "- To evaluate the models based on their accuracy, training time, and generalizability on test data.\n",
    "- To determine the most effective model architecture for this specific application.\n",
    "\n",
    "### Methodology\n",
    "The project will follow these steps:\n",
    "1. Data Preprocessing: Cleaning, tokenizing, and vectorizing the text data.\n",
    "2. Model Building: Constructing three different models with specific architectures.\n",
    "3. Training and Evaluation: Training the models on the dataset and evaluating their performance.\n",
    "4. Comparison and Analysis: Comparing the models based on various performance metrics and providing a comprehensive analysis.\n",
    "\n",
    "This project aims to leverage advanced techniques in natural language processing to solve a practical and relevant challenge in the field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34d9f0",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c0aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2] In ancient philosophy, natura is mostly us...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[3][4] \\nThe concept of nature as a whole, the...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>During the advent of modern scientific method ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5][6] With the Industrial revolution, nature ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>However, a vitalist vision of nature, closer t...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English\n",
       "5  [2] In ancient philosophy, natura is mostly us...  English\n",
       "6  [3][4] \\nThe concept of nature as a whole, the...  English\n",
       "7  During the advent of modern scientific method ...  English\n",
       "8  [5][6] With the Industrial revolution, nature ...  English\n",
       "9  However, a vitalist vision of nature, closer t...  English"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"languages.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad55d5",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addd2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = data['Text'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5da886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "data['Text'] = data['Text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d56e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)  # Remove rows with missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f9d59",
   "metadata": {},
   "source": [
    "# Vectoriztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a9b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)  # Adjust max_features as needed\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdbfae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Initialize the tokenizer with a specified maximum number of words (optional)\n",
    "tokenizer = Tokenizer(num_words=10000)  # Adjust `num_words` as necessary\n",
    "\n",
    "# Assuming 'data' is your DataFrame and it has a column 'Text' that contains the text entries\n",
    "tokenizer.fit_on_texts(data['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c0d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to sequences of integers\n",
    "X_train_seq = tokenizer.texts_to_sequences(data['Text'])\n",
    "\n",
    "# Import the pad_sequences method\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad sequences to ensure uniform input size; adjust 'maxlen' as needed based on your data analysis\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=200)  # 'maxlen' should be chosen based on the length distribution of your texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac9b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(data['Text'])\n",
    "\n",
    "# Convert text to sequences and pad them\n",
    "X_train_seq = tokenizer.texts_to_sequences(data['Text'])\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5812c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Instantiate the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform labels to integer encoded\n",
    "y_encoded = label_encoder.fit_transform(data['Language'])\n",
    "\n",
    "# Convert integer encoded labels to one-hot encoded\n",
    "y_one_hot = to_categorical(y_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40187e9",
   "metadata": {},
   "source": [
    "# Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1202ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model_dense = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_padded.shape[1],)),\n",
    "    Dense(y_one_hot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_dense.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12b507ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\akkin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 270.6005 - accuracy: 0.1034 - val_loss: 4043.5171 - val_accuracy: 0.0106\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 138.1772 - accuracy: 0.1363 - val_loss: 5446.1895 - val_accuracy: 0.0029\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 95.9905 - accuracy: 0.1688 - val_loss: 5512.4751 - val_accuracy: 0.0029\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 73.2890 - accuracy: 0.1934 - val_loss: 5254.6172 - val_accuracy: 0.0019\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 60.9427 - accuracy: 0.2067 - val_loss: 4760.2739 - val_accuracy: 0.0029\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 50.7247 - accuracy: 0.2227 - val_loss: 4384.0771 - val_accuracy: 0.0077\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 42.0632 - accuracy: 0.2366 - val_loss: 3876.0583 - val_accuracy: 0.0106\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 35.8738 - accuracy: 0.2511 - val_loss: 3586.8374 - val_accuracy: 0.0058\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 31.9146 - accuracy: 0.2554 - val_loss: 3125.3157 - val_accuracy: 0.0029\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 27.4766 - accuracy: 0.2648 - val_loss: 2764.4097 - val_accuracy: 0.0058\n"
     ]
    }
   ],
   "source": [
    "# Dense model\n",
    "history_dense = model_dense.fit(X_train_padded, y_one_hot, epochs=10, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60742b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "# Define the model\n",
    "model_cnn = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=50, input_length=200),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_one_hot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad72bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "291/291 [==============================] - 4s 11ms/step - loss: 1.2798 - accuracy: 0.6160 - val_loss: 9.8714 - val_accuracy: 0.1596\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.1354 - accuracy: 0.9665 - val_loss: 10.8430 - val_accuracy: 0.1605\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0721 - accuracy: 0.9794 - val_loss: 11.8640 - val_accuracy: 0.1615\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0618 - accuracy: 0.9805 - val_loss: 12.2929 - val_accuracy: 0.1605\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0574 - accuracy: 0.9814 - val_loss: 13.3916 - val_accuracy: 0.1615\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 13.9524 - val_accuracy: 0.1605\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 14.0647 - val_accuracy: 0.1605\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0550 - accuracy: 0.9827 - val_loss: 14.6992 - val_accuracy: 0.1596\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 14.9055 - val_accuracy: 0.1605\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 3s 10ms/step - loss: 0.0535 - accuracy: 0.9824 - val_loss: 16.3556 - val_accuracy: 0.1605\n"
     ]
    }
   ],
   "source": [
    "# CNN model\n",
    "history_cnn = model_cnn.fit(X_train_padded, y_one_hot, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b71f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Define the model\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=50, input_length=200),\n",
    "    LSTM(64),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_one_hot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53ed48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "291/291 [==============================] - 22s 67ms/step - loss: 1.4575 - accuracy: 0.5352 - val_loss: 9.4746 - val_accuracy: 0.1460\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 0.2482 - accuracy: 0.9346 - val_loss: 10.2017 - val_accuracy: 0.1383\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 0.1156 - accuracy: 0.9728 - val_loss: 11.2149 - val_accuracy: 0.1615\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 0.0825 - accuracy: 0.9775 - val_loss: 10.0033 - val_accuracy: 0.1605\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 19s 66ms/step - loss: 0.0706 - accuracy: 0.9800 - val_loss: 10.8617 - val_accuracy: 0.1586\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 19s 67ms/step - loss: 0.0650 - accuracy: 0.9811 - val_loss: 11.1467 - val_accuracy: 0.1847\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 19s 67ms/step - loss: 0.0609 - accuracy: 0.9820 - val_loss: 10.3457 - val_accuracy: 0.1557\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 19s 67ms/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 9.9467 - val_accuracy: 0.1596\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 19s 66ms/step - loss: 0.0595 - accuracy: 0.9819 - val_loss: 9.2435 - val_accuracy: 0.1576\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 19s 67ms/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 10.2329 - val_accuracy: 0.1625\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "history_lstm = model_lstm.fit(X_train_padded, y_one_hot, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b725d",
   "metadata": {},
   "source": [
    "## Summary of Model Performances and Evaluations\n",
    "\n",
    "### Dense Neural Network:\n",
    "- **Performance**: The Dense model displayed relatively low accuracy with excessively high validation losses, indicating poor generalization and a potential underfitting to the complexities of the language identification task.\n",
    "- **Possible Improvements**: Enhancing the model's complexity, using different vectorization strategies, and incorporating regularization techniques like dropout might improve its performance.\n",
    "\n",
    "### Convolutional Neural Network (CNN):\n",
    "- **Performance**: Exhibited higher accuracy, indicating effective spatial pattern recognition in text data. However, the model's high validation losses suggest significant overfitting.\n",
    "- **Possible Improvements**: Implementing dropout or spatial dropout layers and experimenting with the number of filters or layers could help reduce overfitting and capture more nuanced features.\n",
    "\n",
    "### Long Short-Term Memory (LSTM):\n",
    "- **Performance**: Achieved good accuracy, similar to CNN, but also showed signs of overfitting as indicated by high validation losses. Its architecture is well-suited for capturing long-term dependencies in sequence data, beneficial for processing language.\n",
    "- **Possible Improvements**: Including LSTM-specific dropout strategies and adjusting the number of units or layers could enhance model robustness and performance.\n",
    "\n",
    "## Recommendations and Further Steps:\n",
    "- **Model Selection**: Given their superior performance, both CNN and LSTM are recommended over the Dense model. The choice between CNN and LSTM would depend on specific application needs regarding computational resources and response time.\n",
    "- **Handling Overfitting**: For both CNN and LSTM, applying more rigorous regularization and possibly simplifying the model architectures are crucial steps towards better generalization.\n",
    "- **Further Experimentation**: Exploring hybrid models that combine the strengths of CNNs and LSTMs could potentially offer improvements in learning both spatial and temporal features in the text data.\n",
    "\n",
    "## Concluding Thoughts:\n",
    "All models exhibit potential but also a tendency towards overfitting, highlighting the importance of a balanced approach in model training and architecture design. Fine-tuning these models based on the insights from their performance could lead to more robust solutions for the language identification task.\n",
    "\n",
    "For further analysis or implementation guidance, additional support is available as needed. This documentation ensures clarity in the project's progression and serves as a basis for future enhancements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8f04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
